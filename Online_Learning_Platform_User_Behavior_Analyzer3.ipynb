{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7tgx/0Fmsz4z1X+G7KiyK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/praveen14402/AngulartodoListApp/blob/master/Online_Learning_Platform_User_Behavior_Analyzer3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgSpR_SbeEiZ",
        "outputId": "593bdf8c-2aaa-409b-c427-33f73b94e160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating synthetic online learning platform data...\n",
            "Data generation complete.\n",
            "Dataset shape: (99, 20)\n",
            "Performing Apriori algorithm...\n",
            "Apriori algorithm complete. Found 380 rules.\n",
            "Apriori rules visualization saved as 'apriori_rules_3d.html'.\n",
            "Performing K-means clustering...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rK-means Clustering:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-means iteration 0\n",
            "Intermediate visualization saved as 'user_clusters_3d_step_0.html'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "K-means Clustering:   2%|▏         | 2/100 [00:00<00:09, 10.12it/s]/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K-means iteration 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning:\n",
            "\n",
            "The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "\n",
            "K-means Clustering:   7%|▋         | 7/100 [00:00<00:04, 19.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intermediate visualization saved as 'user_clusters_3d_step_1.html'\n",
            "K-means clustering complete.\n",
            "Final user clusters visual saved as 'user_clusters_3d_final.html'.\n",
            "Analysis complete.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "import random\n",
        "from itertools import combinations\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Initialize Faker for generating realistic course names\n",
        "fake = Faker()\n",
        "\n",
        "def generate_learning_data(num_courses=10, num_users=100, num_interactions=500):\n",
        "    # Generate course names\n",
        "    courses = [fake.word() for _ in range(num_courses)]\n",
        "\n",
        "    interactions = []\n",
        "    for _ in range(num_interactions):\n",
        "        user_id = random.randint(1, num_users)\n",
        "        course = random.choice(courses)\n",
        "        time_spent = random.uniform(0.5, 5.0)  # Time spent in hours\n",
        "        completed = random.choice([0, 1])  # 0: Not Completed, 1: Completed\n",
        "\n",
        "        interactions.append({\n",
        "            'user_id': user_id,\n",
        "            'course': course,\n",
        "            'time_spent': time_spent,\n",
        "            'completed': completed\n",
        "        })\n",
        "\n",
        "    df = pd.DataFrame(interactions)\n",
        "\n",
        "    # Pivot the data to get users' interaction data\n",
        "    df_encoded = df.pivot_table(\n",
        "        index='user_id',\n",
        "        columns='course',\n",
        "        values=['time_spent', 'completed'],\n",
        "        aggfunc={'time_spent': 'sum', 'completed': 'sum'},\n",
        "        fill_value=0\n",
        "    )\n",
        "\n",
        "    # Flatten the MultiIndex columns\n",
        "    df_encoded.columns = ['_'.join(col) for col in df_encoded.columns]\n",
        "\n",
        "    return df_encoded\n",
        "\n",
        "def simple_apriori(df, min_support=0.1, min_confidence=0.5):\n",
        "    def support(item_set):\n",
        "        return (df[list(item_set)].sum(axis=1) >= 1).mean()\n",
        "\n",
        "    items = set(df.columns)\n",
        "    item_sets = [frozenset([item]) for item in items]\n",
        "    rules = []\n",
        "\n",
        "    for k in range(2, len(items) + 1):\n",
        "        item_sets = [s for s in combinations(items, k) if support(s) >= min_support]\n",
        "\n",
        "        for item_set in item_sets:\n",
        "            item_set = frozenset(item_set)\n",
        "            for i in range(1, len(item_set)):\n",
        "                for antecedent in combinations(item_set, i):\n",
        "                    antecedent = frozenset(antecedent)\n",
        "                    consequent = item_set - antecedent\n",
        "                    confidence = support(item_set) / support(antecedent)\n",
        "                    if confidence >= min_confidence:\n",
        "                        lift = confidence / support(consequent)\n",
        "                        rules.append({\n",
        "                            'antecedents': ', '.join(antecedent),\n",
        "                            'consequents': ', '.join(consequent),\n",
        "                            'support': support(item_set),\n",
        "                            'confidence': confidence,\n",
        "                            'lift': lift\n",
        "                        })\n",
        "\n",
        "        if len(rules) >= 10:  # Stop if we have at least 10 rules\n",
        "            break\n",
        "\n",
        "    return pd.DataFrame(rules).sort_values('lift', ascending=False)\n",
        "\n",
        "def perform_kmeans_with_progress(df, n_clusters=3, update_interval=5):\n",
        "    scaler = StandardScaler()\n",
        "    df_scaled = scaler.fit_transform(df)\n",
        "\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, max_iter=100)\n",
        "\n",
        "    with tqdm(total=kmeans.max_iter, desc=\"K-means Clustering\") as pbar:\n",
        "        for i in range(kmeans.max_iter):\n",
        "            kmeans.fit(df_scaled)\n",
        "            pbar.update(1)\n",
        "            if i % update_interval == 0:\n",
        "                yield kmeans.labels_\n",
        "            if kmeans.n_iter_ <= i + 1:\n",
        "                break\n",
        "\n",
        "    return kmeans.labels_\n",
        "\n",
        "def visualize_apriori_rules(rules, top_n=10):\n",
        "    top_rules = rules.head(top_n)\n",
        "\n",
        "    fig = px.scatter_3d(\n",
        "        top_rules, x=\"support\", y=\"confidence\", z=\"lift\",\n",
        "        color=\"lift\", size=\"support\",\n",
        "        hover_name=\"antecedents\", hover_data=[\"consequents\"],\n",
        "        labels={\"support\": \"Support\", \"confidence\": \"Confidence\", \"lift\": \"Lift\"},\n",
        "        title=f\"Top {top_n} Association Rules\"\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def visualize_kmeans_clusters(df, cluster_labels):\n",
        "    pca = PCA(n_components=3)\n",
        "    pca_result = pca.fit_transform(df)\n",
        "\n",
        "    fig = px.scatter_3d(\n",
        "        x=pca_result[:, 0], y=pca_result[:, 1], z=pca_result[:, 2],\n",
        "        color=cluster_labels,\n",
        "        labels={'color': 'Cluster'},\n",
        "        title=\"User Clusters Visualization\"\n",
        "    )\n",
        "\n",
        "    return fig\n",
        "\n",
        "def main():\n",
        "    print(\"Generating synthetic online learning platform data...\")\n",
        "    df_encoded = generate_learning_data(num_courses=10, num_users=100, num_interactions=500)\n",
        "    print(\"Data generation complete.\")\n",
        "    print(f\"Dataset shape: {df_encoded.shape}\")\n",
        "\n",
        "    print(\"Performing Apriori algorithm...\")\n",
        "    rules = simple_apriori(df_encoded, min_support=0.1, min_confidence=0.5)\n",
        "\n",
        "    if not rules.empty:\n",
        "        print(f\"Apriori algorithm complete. Found {len(rules)} rules.\")\n",
        "        viz = visualize_apriori_rules(rules)\n",
        "        viz.write_html(\"apriori_rules_3d.html\")\n",
        "        print(\"Apriori rules visualization saved as 'apriori_rules_3d.html'.\")\n",
        "    else:\n",
        "        print(\"Apriori algorithm failed to generate rules.\")\n",
        "\n",
        "    print(\"Performing K-means clustering...\")\n",
        "    kmeans_generator = perform_kmeans_with_progress(df_encoded, n_clusters=3, update_interval=5)\n",
        "    for i, labels in enumerate(kmeans_generator):\n",
        "        print(f\"K-means iteration {i*5}\")\n",
        "        viz = visualize_kmeans_clusters(df_encoded, labels)\n",
        "        viz.write_html(f\"user_clusters_3d_step_{i}.html\")\n",
        "        print(f\"Intermediate visualization saved as 'user_clusters_3d_step_{i}.html'\")\n",
        "\n",
        "    final_labels = labels  # The last generated labels\n",
        "    print(\"K-means clustering complete.\")\n",
        "    final_viz = visualize_kmeans_clusters(df_encoded, final_labels)\n",
        "    final_viz.write_html(\"user_clusters_3d_final.html\")\n",
        "    print(\"Final user clusters visual saved as 'user_clusters_3d_final.html'.\")\n",
        "\n",
        "    print(\"Analysis complete.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R1czkyHceFtE",
        "outputId": "df5b4ecd-f0e5-4de1-f07e-df85e9182ca5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement itertools (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for itertools\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZM8kEe8E_2c5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}